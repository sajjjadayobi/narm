# Course Baseline
  - Stanford 2021 as [baseline](http://web.stanford.edu/class/cs224n/)
  - Transformers
    - Tokenizers:
      - byte pair encdoing , ...
    - positinal encoding
    - gule activation function
    - all type of normalization
    - AdamW
  - Bert
    - LMs (AR, Masked)
    - Contextual Embeddings
    - next sentence prediction
    - CLS token
  - Hugging Face
    - pipeline
    - how use
      - Trainer
    - fine-tune 
      - text classification
  - Roberta
  - Albert
  - GPT 2 & 3
  - T5
  
  - OPTINALS
    - Multilingual Transformers
    - distil-Bert
    - Fast-Training
    - LongFormer
    - Question Answering
  
    
# Rules:
  - for any topics
    - see original paper
    - search for paper explaner
    - see other blog post
    - and search it on Youtube


# [Stanford](https://www.youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z): Natural Language Processing with Deep Learning
- Transformers
- Bert
- My Notes

# [Yanick](https://www.youtube.com/channel/UCZHmQk67mSJgfCCTn7xBfew): 
- Transformers
- Bert
- GPT-2-3
- Roberta
- T5
- LayerNorm

# [Lecun Course](https://www.youtube.com/playlist?list=PLLHTzKZzVU9eaEyErdV26ikyolxOsz6mq)
- Transformers

# [jalammar](http://jalammar.github.io/)
- Transformers
- Bert
- Language Models interpruter
- GPT-2-3

# [dive to ai](https://d2l.ai)
- Transformers
- Bert (with training)

# Single
- [Albert](https://amitness.com/2020/02/albert-visual-summary) from chaudhary
- [Transfromers](lena-voita.github.io) lena


